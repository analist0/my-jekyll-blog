#!/usr/bin/env python3
"""
AI Article Generator for Jekyll Blog
Uses X (Twitter) API v2 to find trending AI topics
Generates comprehensive Hebrew articles using OpenAI API
"""

import os
import sys
import json
import requests
from datetime import datetime
from pathlib import Path
import re

# Configuration
X_API_BEARER_TOKEN = os.getenv('X_API_BEARER_TOKEN')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')  # Fallback to OpenAI if needed
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')  # Claude API

# X API v2 Endpoint
X_API_URL = "https://api.twitter.com/2/tweets/search/recent"

# AI Keywords to search
AI_KEYWORDS = [
    "ChatGPT", "GPT-4", "Claude", "Anthropic", "OpenAI",
    "LLM", "Large Language Model", "Mistral AI", "Llama",
    "Gemini", "Google AI", "DeepMind", "AI breakthrough",
    "machine learning", "deep learning", "neural network",
    "artificial intelligence", "AI model", "AI research",
    "transformer", "diffusion model", "GPT", "local LLM",
    "Ollama", "open source AI", "AI safety", "AGI"
]

def search_trending_ai_topics():
    """Search X (Twitter) for trending AI topics using API v2"""

    if not X_API_BEARER_TOKEN:
        print("âš ï¸  X_API_BEARER_TOKEN not set, using fallback keywords")
        # Fallback: return top AI keywords
        return [
            "Latest AI Breakthroughs in Machine Learning",
            "Advanced Neural Network Developments",
            "Ethical AI and Responsible Development Trends"
        ]

    headers = {
        "Authorization": f"Bearer {X_API_BEARER_TOKEN}",
        "User-Agent": "AI-Blog-Generator/1.0"
    }

    # Search query - combined AI keywords
    query = " OR ".join(AI_KEYWORDS[:10])  # Use first 10 keywords to avoid query length limit

    params = {
        "query": f"({query}) -is:retweet lang:en",
        "max_results": 100,
        "tweet.fields": "public_metrics,created_at",
        "sort_order": "relevancy"
    }

    try:
        response = requests.get(X_API_URL, headers=headers, params=params, timeout=15)
        response.raise_for_status()
        data = response.json()

        if "data" not in data or not data["data"]:
            print("âš ï¸  No tweets found, using fallback topics")
            return [
                "Latest AI Breakthroughs in Machine Learning",
                "Advanced Neural Network Developments",
                "Ethical AI and Responsible Development Trends"
            ]

        # Analyze tweets and extract trending topics
        topics = analyze_tweets(data["data"])
        return topics[:3]  # Top 3 topics

    except Exception as e:
        print(f"âŒ Error fetching from X API: {e}")
        # Fallback topics
        return [
            "Latest AI Breakthroughs in Machine Learning",
            "Advanced Neural Network Developments",
            "Ethical AI and Responsible Development Trends"
        ]

def analyze_tweets(tweets):
    """Analyze tweets to extract trending topics"""
    # Simple analysis: extract most common phrases
    topics = {}

    for tweet in tweets:
        text = tweet.get("text", "")

        # Extract potential topics (simplified)
        for keyword in AI_KEYWORDS:
            if keyword.lower() in text.lower():
                if keyword not in topics:
                    topics[keyword] = 0
                topics[keyword] += 1

    # Sort by frequency
    sorted_topics = sorted(topics.items(), key=lambda x: x[1], reverse=True)

    # Generate topic titles
    topic_titles = []
    for topic, count in sorted_topics[:5]:
        if "GPT" in topic or "Claude" in topic:
            topic_titles.append(f"Latest Developments in {topic} Technology")
        elif "AI" in topic:
            topic_titles.append(f"Breaking News: {topic} Innovations")
        else:
            topic_titles.append(f"Deep Dive: {topic} in Modern AI")

    return topic_titles if topic_titles else [
        "Latest AI Breakthroughs in Machine Learning",
        "Advanced Neural Network Developments",
        "Ethical AI and Responsible Development Trends"
    ]

def generate_article_content(topic):
    """Generate comprehensive Hebrew article using AI"""

    prompt = f"""×›×ª×•×‘ ××××¨ ××§×™×£ ×•××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª ×¢×œ ×”× ×•×©×: "{topic}"

×”×“×¨×™×©×•×ª:
1. ××××¨ ×‘××•×¨×š 1500-2000 ××™×œ×™×
2. ×›×ª×™×‘×” ××§×¦×•×¢×™×ª ×‘×¨××” ×’×‘×•×”×”
3. ×”×¡×‘×¨×™× ××¤×•×¨×˜×™× ×•×¢×•××§ ×˜×›× ×™
4. ××‘× ×” ×‘×¨×•×¨ ×¢× ×›×•×ª×¨×•×ª ××©× ×” (H2, H3)
5. ×“×•×’×××•×ª ××¢×©×™×•×ª ×•××§×¨×™ ×©×™××•×©
6. ×¤×¡×§×ª ×¤×ª×™×—×” ××¨×ª×§×ª
7. ×¡×™×›×•× ××§×™×£ ×‘×¡×•×£
8. ×©×™××•×© ×‘-markdown ×œ×¢×™×¦×•×‘
9. ×§×•×“ ×œ×“×•×’××” ×‘××™×“×ª ×”×¦×•×¨×š (×¢× ×”×¡×‘×¨×™×)
10. ×”×ª×™×™×—×¡×•×ª ×œ××’××•×ª ×¢×“×›× ×™×•×ª ×‘-AI

×”××××¨ ×¦×¨×™×š ×œ×›×œ×•×œ:
- ×”×§×“××” ××¢× ×™×™× ×ª ×©××•×©×›×ª ××ª ×”×§×•×¨×
- ×”×¡×‘×¨ ××” ×”×˜×›× ×•×œ×•×’×™×”/× ×•×©× ×•××“×•×¢ ×”×•× ×—×©×•×‘
- ×”×¡×‘×¨ ×˜×›× ×™ ××¢××™×§ ××š × ×’×™×©
- ×™×™×©×•××™× ××¢×©×™×™× ×•×“×•×’×××•×ª
- ×”×©×•×•××•×ª ×œ××•×¦×¨×™×/×˜×›× ×•×œ×•×’×™×•×ª ××—×¨×•×ª
- ××ª×’×¨×™× ×•×”×–×“×× ×•×™×•×ª
- ××’××•×ª ×¢×ª×™×“×™×•×ª
- ×¡×™×›×•× ×—×–×§

×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ª×§× ×™×ª, ××§×¦×•×¢×™×ª, ×¢× ×¡×’× ×•×Ÿ ×›×ª×™×‘×” ××•×©×š ×•× ×¢×™× ×œ×§×¨×™××”.
"""

    # Try Claude API first (better for Hebrew)
    if ANTHROPIC_API_KEY:
        try:
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers={
                    "x-api-key": ANTHROPIC_API_KEY,
                    "anthropic-version": "2023-06-01",
                    "content-type": "application/json"
                },
                json={
                    "model": "claude-3-5-sonnet-20241022",
                    "max_tokens": 4000,
                    "messages": [{"role": "user", "content": prompt}]
                },
                timeout=60
            )
            response.raise_for_status()
            data = response.json()
            content = data["content"][0]["text"]
            print("âœ… Generated article using Claude API")
            return content
        except Exception as e:
            print(f"âš ï¸  Claude API failed: {e}")

    # Fallback to OpenAI
    if OPENAI_API_KEY:
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "gpt-4-turbo-preview",
                    "messages": [{"role": "user", "content": prompt}],
                    "max_tokens": 3000,
                    "temperature": 0.7
                },
                timeout=60
            )
            response.raise_for_status()
            data = response.json()
            content = data["choices"][0]["message"]["content"]
            print("âœ… Generated article using OpenAI API")
            return content
        except Exception as e:
            print(f"âš ï¸  OpenAI API failed: {e}")

    # Final fallback: template article
    print("âš ï¸  Using template article (no API keys available)")
    return generate_template_article(topic)

def generate_template_article(topic):
    """Generate a template article when APIs are unavailable"""
    return f"""# {topic}

## ××‘×•×

×¢×•×œ× ×”×‘×™× ×” ×”××œ××›×•×ª×™×ª ×××©×™×š ×œ×”×ª×¤×ª×— ×‘×§×¦×‘ ××”×™×¨, ×•×”× ×•×©× ×©×œ **{topic}** ×”×•× ××—×“ ×”×ª×—×•××™× ×”××¨×ª×§×™× ×•×”×—×©×•×‘×™× ×‘×™×•×ª×¨ ×›×™×•×.

## ××” ×–×” {topic}?

{topic} ××™×™×¦×’ ×”×ª×§×“××•×ª ××©××¢×•×ª×™×ª ×‘×ª×—×•× ×”×‘×™× ×” ×”××œ××›×•×ª×™×ª. ×˜×›× ×•×œ×•×’×™×” ×–×• ××©× ×” ××ª ×”×“×¨×š ×‘×” ×× ×—× ×• ×—×•×©×‘×™× ×¢×œ ××¢×¨×›×•×ª AI ×•×™×™×©×•××™×”×Ÿ ×‘×¢×•×œ× ×”××•×“×¨× ×™.

### ×”×™×¡×˜×•×¨×™×” ×§×¦×¨×”

×”×¤×™×ª×•×— ×©×œ ×˜×›× ×•×œ×•×’×™×•×ª AI ×¢×‘×¨ ×“×¨×š ××¨×•×›×”, ××ª×§×•×¤×ª ×”××—×§×¨ ×”××•×§×“× ×‘-1950s ×•×¢×“ ×œ×”×ª×¤×ª×—×•×™×•×ª ×”××•×“×¨× ×™×•×ª ×©×œ ×”×™×•×.

## ×™×™×©×•××™× ××¢×©×™×™×

×˜×›× ×•×œ×•×’×™×” ×–×• ××©××©×ª ×‘××’×•×•×Ÿ ×ª×—×•××™×:

1. **×¢×™×‘×•×“ ×©×¤×” ×˜×‘×¢×™×ª (NLP)** - ×”×‘× ×ª ×˜×§×¡×˜ ×•×©×™×—×” ×× ×•×©×™×ª
2. **×¨××™×™×” ×××•×—×©×‘×ª** - ×–×™×”×•×™ ×ª××•× ×•×ª ×•×•×™×“××•
3. **×œ××™×“×” ××ª××©×›×ª** - ×©×™×¤×•×¨ ×‘×™×¦×•×¢×™× ×œ××•×¨×š ×–××Ÿ
4. **××¢×¨×›×•×ª ×”××œ×¦×”** - ×”×ª×××” ××™×©×™×ª ×œ×›×œ ××©×ª××©

## ××ª×’×¨×™×

×œ××¨×•×ª ×”×”×ª×§×“××•×ª ×”××¨×©×™××”, ×¢×“×™×™×Ÿ ×§×™×™××™× ××ª×’×¨×™×:

- **×¢×œ×•×™×•×ª ×—×™×©×•×‘ ×’×‘×•×”×•×ª** - ××™××•×Ÿ ××•×“×œ×™× ×’×“×•×œ×™× ×“×•×¨×© ××©××‘×™× ×¨×‘×™×
- **××™×›×•×ª × ×ª×•× ×™×** - ×ª×œ×•×ª ×‘× ×ª×•× ×™ ××™××•×Ÿ ××™×›×•×ª×™×™×
- **×©×§×™×¤×•×ª ×•×”×¡×‘×¨×™×** - ×”×‘× ×ª ×”×—×œ×˜×•×ª ×”××•×“×œ
- **××ª×™×§×” ×•×¤×¨×˜×™×•×ª** - ×©××™×¨×” ×¢×œ ×¢×¨×›×™× ×× ×•×©×™×™×

## ××’××•×ª ×¢×ª×™×“×™×•×ª

×”×¢×ª×™×“ × ×¨××” ××‘×˜×™×— ×¢×:

- ××•×“×œ×™× ×—×¡×›×•× ×™×™× ×•×™×¢×™×œ×™× ×™×•×ª×¨
- AI ××§×•××™ (Local LLMs)
- ×©×™×œ×•×‘ ×˜×•×‘ ×™×•×ª×¨ ×¢× ××¢×¨×›×•×ª ×§×™×™××•×ª
- × ×’×™×©×•×ª ×¨×—×‘×” ×™×•×ª×¨ ×œ××¤×ª×—×™×

## ×¡×™×›×•×

{topic} ×”×•× ×ª×—×•× ××¨×ª×§ ×‘×¢×•×œ× ×”-AI ×©×××©×™×š ×œ×”×ª×¤×ª×—. ×”×”×‘× ×” ×©×œ ×”×˜×›× ×•×œ×•×’×™×•×ª ×”×œ×œ×• ×—×™×•× ×™×ª ×œ×›×œ ××™ ×©××¢×•× ×™×™×Ÿ ×œ×”×™×©××¨ ××¢×•×“×›×Ÿ ×‘×¢×•×œ× ×”×˜×›× ×•×œ×•×’×™×” ×”××•×“×¨× ×™×ª.

---

*××××¨ ×–×” ×¢×•×“×›×Ÿ ×‘-{datetime.now().strftime("%d.%m.%Y")}*
"""

def create_jekyll_post(topic, content, index):
    """Create Jekyll post file with proper front matter"""

    # Create filename
    date_str = datetime.now().strftime("%Y-%m-%d")
    time_str = datetime.now().strftime("%H%M%S")
    slug = re.sub(r'[^a-z0-9]+', '-', topic.lower())
    slug = slug.strip('-')[:50]  # Limit length

    filename = f"{date_str}-{slug}---{time_str}-{index}.md"

    # Generate tags
    tags = ["AI", "×‘×™× ×” ××œ××›×•×ª×™×ª", "×˜×›× ×•×œ×•×’×™×”", "Machine Learning"]
    if "GPT" in topic:
        tags.append("GPT")
    if "neural" in topic.lower():
        tags.extend(["Neural Networks", "×¨×©×ª×•×ª × ×•×™×¨×•× ×™×"])
    if "ethical" in topic.lower():
        tags.extend(["AI Ethics", "××ª×™×§×”"])

    # Front matter
    front_matter = f"""---
layout: post
title: "{topic}"
date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} +0300
categories: ["AI", "Technology"]
tags: {json.dumps(tags, ensure_ascii=False)}
author: "analist0"
description: "××××¨ ××§×™×£ ×¢×œ {topic} - ×”×˜×›× ×•×œ×•×’×™×”, ×”×™×™×©×•××™×, ×•×”××’××•×ª ×”×¢×“×›× ×™×•×ª ×‘×ª×—×•× ×”×‘×™× ×” ×”××œ××›×•×ª×™×ª"
excerpt: "{content[:200].replace(chr(10), ' ')}..."
---

"""

    # Combine front matter and content
    full_content = front_matter + content

    # Write to _posts directory
    posts_dir = Path(__file__).parent.parent / "_posts"
    posts_dir.mkdir(exist_ok=True)

    filepath = posts_dir / filename
    filepath.write_text(full_content, encoding='utf-8')

    print(f"âœ… Created post: {filename}")
    return filename

def main():
    """Main function"""
    print("ğŸ¤– AI Article Generator Starting...")
    print("=" * 50)

    # Step 1: Search trending topics
    print("\nğŸ“Š Step 1: Searching trending AI topics on X...")
    topics = search_trending_ai_topics()
    print(f"âœ… Found {len(topics)} topics:")
    for i, topic in enumerate(topics, 1):
        print(f"   {i}. {topic}")

    # Step 2: Generate articles
    print("\nâœï¸  Step 2: Generating articles...")
    created_files = []

    for index, topic in enumerate(topics):
        print(f"\nğŸ“ Generating article {index + 1}/{len(topics)}: {topic}")
        try:
            content = generate_article_content(topic)
            filename = create_jekyll_post(topic, content, index)
            created_files.append(filename)
            print(f"   âœ… Success: {filename}")
        except Exception as e:
            print(f"   âŒ Error: {e}")
            continue

    # Step 3: Summary
    print("\n" + "=" * 50)
    print(f"âœ… Generated {len(created_files)} articles:")
    for filename in created_files:
        print(f"   â€¢ {filename}")

    print("\nğŸ‰ Article generation complete!")
    return 0

if __name__ == "__main__":
    sys.exit(main())
