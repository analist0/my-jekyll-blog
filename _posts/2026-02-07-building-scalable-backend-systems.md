---
layout: post-modern
title: "Building Scalable Backend Systems"
description: "××“×¨×™×š ××§×™×£ ×•××¤×•×¨×˜ ×¢×œ Building Scalable Backend Systems. ×›×•×œ×œ ×”×¡×‘×¨×™×, ×“×•×’×××•×ª ×§×•×“ ××œ××•×ª, best practices ×•×¤×¨×•×™×§×˜ ××¢×©×™."
date: 2026-02-07 09:37:23 +0200
categories: ["Tutorial", "Development"]
tags: ["building", "scalable", "backend", "systems"]
author: "analist0"
lang: he
dir: rtl
image: "https://imgen.x.ai/xai-imgen/xai-tmp-imgen-971a7582-789d-4f91-83c1-46ad4fb6a34f.jpeg"
---

## ğŸ¯ ×¡×§×™×¨×” ×›×œ×œ×™×ª

×‘× ×™×™×ª **××¢×¨×›×•×ª backend ××“×¨×’×™×•×ª (Scalable Backend Systems)** ×”×™× ××—×“ ×”××ª×’×¨×™× ×”××¨×›×–×™×™× ×‘×¤×™×ª×•×— ×ª×•×›× ×” ××•×“×¨× ×™. ××¢×¨×›×ª backend ××“×¨×’×™×ª ×”×™× ×›×–×• ×©××¡×•×’×œ×ª ×œ×”×ª××•×“×“ ×¢× **×¢×•××¡ ×’×•×‘×¨ ×©×œ ××©×ª××©×™×, ×‘×§×©×•×ª ×•× ×ª×•× ×™×** ××‘×œ×™ ×œ×¤×’×•×¢ ×‘×‘×™×¦×•×¢×™×, ×–××™× ×•×ª ××• ×¢×œ×•×™×•×ª ×ª×¤×¢×•×œ. ×”×™× ××‘×•×¡×¡×ª ×¢×œ ×¢×§×¨×•× ×•×ª ×›××• **×”×¤×¨×“×” ×©×œ ×©×™×¨×•×ª×™× (Microservices)**, **×©×›×¤×•×œ ××•×¤×§×™ (Horizontal Scaling)**, **××˜××•×Ÿ (Caching)**, **×ª×•×¨×™× Ğ°Ñ×™× ×›×¨×•× ×™×™× (Async Queues)** ×•**××™×–×•×Ÿ ×¢×•××¡ (Load Balancing)**.

### ×œ××” ×–×” ×—×©×•×‘?
×‘×¢×•×œ× ×”×“×™×’×™×˜×œ×™ ×©×œ ×”×™×•×, ××¤×œ×™×§×¦×™×•×ª ×›××• **Netflix**, **Uber** ××• **Amazon** ×—×™×™×‘×•×ª ×œ×©×¨×ª ××™×œ×™×•× ×™ ××©×ª××©×™× ×‘×•-×–×× ×™×ª. ××¢×¨×›×ª ×œ× ××“×¨×’×™×ª ×ª×§×¨×•×¡ ×ª×—×ª ×¢×•××¡ (×›××• ×©×§×¨×” ×œ-Twitter ×‘××”×œ×š ××™×¨×•×¢×™× ×’×“×•×œ×™×). ×™×ª×¨×•× ×•×ª ××¨×›×–×™×™×:
- **×–××™× ×•×ª ×’×‘×•×”×” (High Availability)**: 99.99% uptime.
- **×’××™×©×•×ª**: ×”×•×¡×¤×ª ×©×¨×ª×™× ×‘×§×œ×•×ª.
- **×—×™×¡×›×•×Ÿ ×‘×¢×œ×•×™×•×ª**: ×©×™××•×© ×‘××©××‘×™× ×“×™× ××™ (Auto-scaling).
- **×ª×—×–×•×§×” ×§×œ×”**: ××™×§×¨×•-×©×™×¨×•×ª×™× ×××¤×©×¨×™× ×¢×“×›×•× ×™× ×¢×¦×××™×™×.

### ×ª×¨×—×™×©×™ ×©×™××•×© ××”×¢×•×œ× ×”×××™×ª×™
1. **×¤×œ×˜×¤×•×¨××ª ×¡×˜×¨×™××™× ×’ ×›××• Netflix**: ×©×™××•×© ×‘-**microservices** ×¢× **Kubernetes** ×œ× ×™×”×•×œ ××œ×¤×™ ×¤×•×“×™×, **Cassandra** ×œ× ×ª×•× ×™× ××‘×•×–×¨×™× ×•-**CDN** ×œ×”×¤×¦×ª ×ª×•×›×Ÿ.
2. **××¤×œ×™×§×¦×™×™×ª ×¨×›×‘ ×©×™×ª×•×¤×™ ×›××• Uber**: **Kafka** ×œ×ª×•×¨×™× Ğ°ÑĞ¸Ğ½×›×¨×•× ×™×™× ×œ×¢×™×‘×•×“ ×”×–×× ×•×ª, **Redis** ×œ××˜××•×Ÿ ××™×§×•××™× ×‘×–××Ÿ ×××ª, **PostgreSQL** ×©×›×¤×•×œ ×©×•×œ×—× ×™.
3. **×—× ×•×ª ××§×•×•× ×ª ×›××• Amazon**: **Serverless** ×¢× AWS Lambda ×œ×‘×§×©×•×ª ×§×˜× ×•×ª, **DynamoDB** ×œ× ×ª×•× ×™× NoSQL, **ELB** (Elastic Load Balancer) ×œ××™×–×•×Ÿ.
4. **×¨×©×ª ×—×‘×¨×ª×™×ª ×›××• Twitter**: **GraphQL Federation** ×œ×©×™×¨×•×ª×™× ××‘×•×–×¨×™×, **Memcached** ×œ××˜××•×Ÿ ×¤×™×“×™×.
5. **××¢×¨×›×ª IoT**: **MQTT broker** ×›××• EMQX ×œ××™×œ×™×•× ×™ ×—×™×‘×•×¨×™×, **TimescaleDB** ×œ× ×ª×•× ×™ ×–××Ÿ.

### ×”×©×•×•××” ×§×¦×¨×” ×œ××œ×˜×¨× ×˜×™×‘×•×ª
| ××¨×›×™×˜×§×˜×•×¨×” | ×™×ª×¨×•× ×•×ª | ×—×¡×¨×•× ×•×ª | ××ª××™× ×œ... |
|--------------|----------|-----------|-------------|
| **Monolithic** | ×¤×™×ª×•×— ××”×™×¨, ×¤×¨×™×¡×” ×¤×©×•×˜×” | ×§×©×” ×œ×”×¨×—×‘×”, ×ª×œ×•×ª ×”×“×“×™×ª | ××¤×œ×™×§×¦×™×•×ª ×§×˜× ×•×ª |
| **Microservices** | ××“×¨×’×™×•×ª ×’×‘×•×”×”, ×¢×¦×××•×ª | ××•×¨×›×‘×•×ª ×ª×¤×¢×•×œ×™×ª, latency ×¨×©×ª | ××¨×’×•× ×™× ×’×“×•×œ×™× |
| **Serverless** | ×œ×œ× × ×™×”×•×œ ×©×¨×ª×™×, Auto-scale | Cold starts, vendor lock-in | workloads ××™×¨×•×¢×™×™× |
| **Event-Driven** | Ğ°Ñ×™× ×›×¨×•× ×™, ×¢××™×“×•×ª | ×“×™×‘××’ ×§×©×” | ××¢×¨×›×•×ª real-time |

> **×˜×™×¤**: ×‘×—×¨ ××¨×›×™×˜×§×˜×•×¨×” ×œ×¤×™ ×’×•×“×œ ×”×¦×•×•×ª ×•×”×¢×•××¡ ×”×¦×¤×•×™. ×”×ª×—×œ ×¢× monolith ×•×”×ª×§×“× ×œ-microservices.

## ğŸ’» ×“×¨×™×©×•×ª ××¢×¨×›×ª ×•×”×›× ×”

×‘× ×™×™×ª ××¢×¨×›×ª backend ××“×¨×’×™×ª ×“×•×¨×©×ª ×¡×‘×™×‘×ª ×¤×™×ª×•×— ×•×¤×¨×•×“×§×©×Ÿ ×—×–×§×”. ×œ×”×œ×Ÿ ×“×¨×™×©×•×ª ××™× ×™××œ×™×•×ª ×œ×¤×¨×•×“×§×©×Ÿ (×œ×©×¨×ª EC2 m5.large ×‘-AWS ×›×“×•×’××”).

### ×˜×‘×œ×ª ×“×¨×™×©×•×ª ××¢×¨×›×ª
| ×¨×›×™×‘ | ××™× ×™××•× | ××•××œ×¥ (×¤×¨×•×“×§×©×Ÿ) | ×”×¢×¨×•×ª |
|------|----------|-------------------|--------|
| **CPU** | 2 cores | 8+ cores (vCPU) | Intel/AMD ×¢× AVX2 ×œ-Node.js |
| **RAM** | 4 GB | 32+ GB | ×œ-clustering ×•-caching |
| **Storage** | 50 GB SSD | 500 GB NVMe + EBS | Docker images + DB data |
| **OS** | Ubuntu 22.04 LTS / macOS Ventura | Ubuntu 22.04 / RHEL 9 | Linux kernel 5.15+ ×œ-eBPF |
| **×¨×©×ª** | 1 Gbps | 10 Gbps | Low latency ×œ-microservices |

### ×›×œ×™× × ×“×¨×©×™× + ×’×¨×¡××•×ª
- **Node.js**: v18.17+ (LTS)
- **Docker**: v20.10+
- **Docker Compose**: v2.20+
- **Kubernetes (Minikube)**: v1.28+
- **Git**: v2.39+
- **npm/yarn**: npm 9+ / yarn 1.22+
- **PostgreSQL**: v15+
- **Redis**: v7.0+
- **Nginx**: v1.24+

### ×¤×§×•×“×•×ª ×”×›× ×” (Linux/macOS)
×”×ª×§×Ÿ ×”×›×œ ×¢× script ××•×˜×•××˜×™:

```bash
#!/bin/bash
# Update system and install prerequisites
sudo apt update && sudo apt upgrade -y
sudo apt install -y curl wget git build-essential

# Install Node.js 18 via nodesource
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt install -y nodejs

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Install Minikube and kubectl
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install kubectl /usr/local/bin/kubectl

# Verify installations
node --version && docker --version && docker-compose --version && minikube version
```

> **×”×¢×¨×” ×—×©×•×‘×”**: ×‘-Windows ×”×©×ª××© ×‘-WSL2 + Ubuntu. ×”×¤×¢×œ `wsl --install` ×‘-PowerShell ×›×× ×”×œ.

## ğŸ“¦ ×”×ª×§× ×” ×•×”×’×“×¨×” - ×¦×¢×“ ××—×¨ ×¦×¢×“

### ×”×ª×§× ×” ×‘-Linux/macOS
1. ×”×¨×¥ ××ª script ×”×”×›× ×” ××œ××¢×œ×”.
2. ×”×ª×§×Ÿ PostgreSQL ×•-Redis:
   ```bash
   sudo apt install -y postgresql postgresql-contrib redis-server
   sudo systemctl start postgresql redis-server
   sudo systemctl enable postgresql redis-server
   ```
3. ×”×’×“×¨ DB:
   ```bash
   sudo -u postgres psql -c "CREATE DATABASE scalable_backend;"
   sudo -u postgres psql -c "CREATE USER backend_user WITH PASSWORD 'securepass';"
   sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE scalable_backend TO backend_user;"
   ```

### ×”×ª×§× ×” ×‘-Windows (WSL2)
1. ×”×ª×§×Ÿ WSL2: `wsl --install -d Ubuntu`.
2. ×¤×ª×— Ubuntu ×•×”×¨×¥ ××ª script Linux.

### ×”×ª×§× ×” ×¢× Docker (××•××œ×¥ ×œ×¤×¨×•×“×§×©×Ÿ)
×¦×•×¨ `docker-compose.yml` ×œ-stack ××œ×:

```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DB_HOST=db
    depends_on:
      - db
      - redis
    deploy:
      replicas: 3  # Horizontal scaling

  db:
    image: postgres:15
    environment:
      POSTGRES_DB: scalable_backend
      POSTGRES_USER: backend_user
      POSTGRES_PASSWORD: securepass
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes

  nginx:
    image: nginx:1.24-alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app

volumes:
  postgres_data:
```

×”×¤×¢×œ: `docker-compose up -d --scale app=3`.

## ğŸš€ ×©×™××•×© ×‘×¡×™×¡×™ - Hello World

×“×•×’××” ×¨××©×•× ×”: ×©×¨×ª **Express.js** ×¤×©×•×˜ ×¢× clustering.

×¦×•×¨ `server.js`:

```javascript
const express = require('express');
const cluster = require('cluster');
const os = require('os');
const app = express();
const numCPUs = os.cpus().length;

// Worker processes
if (cluster.isWorker) {
  app.get('/', (req, res) => {
    res.json({ message: 'Hello Scalable World!', pid: process.pid });
  });

  app.listen(3000, () => {
    console.log(`Worker ${process.pid} started on port 3000`);
  });
} else {
  // Master process - fork workers
  console.log(`Master ${process.pid} starting ${numCPUs} workers...`);
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }

  cluster.on('exit', (worker) => {
    console.log(`Worker ${worker.process.pid} died. Restarting...`);
    cluster.fork();
  });
}
```

×”×¤×¢×œ: `npm init -y && npm i express && node server.js`.

### ×”×¡×‘×¨ ×©×•×¨×” ××—×¨ ×©×•×¨×”
- `cluster.isWorker`: ×‘×•×“×§ ×× ×ª×”×œ×™×š ×”×•× worker.
- `os.cpus().length`: ××¡×¤×¨ ×œ×™×‘×•×ª CPU ×œ×”×§××” ××•×¤×˜×™××œ×™×ª.
- Master fork workers â€“ **××“×¨×’×™ ××•×¤×§×™ ×¨××©×•× ×™**.
- `app.get('/')`: endpoint ×‘×¡×™×¡×™ ×¢× PID ×œ×–×™×”×•×™ worker.
- `cluster.on('exit')`: **Zero-downtime restarts**.

×‘×“×•×§ ×¢× `curl localhost:3000` â€“ ×ª×§×‘×œ ×ª×’×•×‘×” ×-worker ×©×•× ×” ×‘×›×œ ×¤×¢×.

## âš¡ ×©×™××•×© ××ª×§×“×

### 1. ××™× ×˜×’×¨×¦×™×” ×¢× Redis ×œ××˜××•×Ÿ
×”×•×¡×£ caching ×œ×©×¨×ª:

```javascript
const express = require('express');
const redis = require('redis');
const app = express();

const client = redis.createClient({
  url: 'redis://localhost:6379'
});
client.connect();

app.get('/users/:id', async (req, res) => {
  const { id } = req.params;
  const cached = await client.get(`user:${id}`);

  if (cached) {
    return res.json(JSON.parse(cached));
  }

  // Simulate DB fetch
  const user = { id, name: `User ${id}`, email: `user${id}@example.com` };
  await client.setEx(`user:${id}`, 3600, JSON.stringify(user));  // TTL 1h

  res.json(user);
});

app.listen(3001, () => console.log('Advanced server on 3001'));
```

×”×ª×§×Ÿ: `npm i redis`.

### 2. ×ª×•×¨×™× Ğ°ÑĞ¸Ğ½×›×¨×•× ×™×™× ×¢× BullMQ
×¢×‘×•×¨ ××©×™××•×ª ×›×‘×“×•×ª (e.g. email sending):

```javascript
const Queue = require('bullmq').Queue;
const { Worker } = require('bullmq');

const emailQueue = new Queue('emails', { connection: { host: 'localhost', port: 6379 } });

// Producer
app.post('/send-email', async (req, res) => {
  await emailQueue.add('send', { to: 'user@example.com', subject: 'Welcome' });
  res.json({ status: 'queued' });
});

// Worker (×§×•×‘×¥ × ×¤×¨×“: worker.js)
const emailWorker = new Worker('emails', async job => {
  console.log(`Sending email to ${job.data.to}`);
  // Integrate with Nodemailer here
}, { connection: { host: 'localhost', port: 6379 } });
```

×”×ª×§×Ÿ: `npm i bullmq`.

### 3. Load Balancing ×¢× Nginx
`nginx.conf`:
```
events { worker_connections 1024; }
http {
  upstream backend {
    least_conn;  # Algorithm
    server app1:3000;
    server app2:3000;
    server app3:3000;
  }
  server {
    listen 80;
    location / { proxy_pass http://backend; }
  }
}
```

### 4. Design Patterns
- **Circuit Breaker** (×¢× `opossum`): ×× ×¢ cascading failures.
- **Saga Pattern** ×œ-microservices transactions.
- **CQRS + Event Sourcing** ×¢× Kafka.

> **×˜×™×¤ ××ª×§×“×**: ×”×©×ª××© ×‘-**gRPC** ×‘××§×•× REST ×œ-low latency ×‘×™×Ÿ ×©×™×¨×•×ª×™×.

## ğŸ—ï¸ ×¤×¨×•×™×§×˜ ××¢×©×™ ××œ×

×‘×•××• × ×‘× ×” **API ×œ× ×™×”×•×œ ××©×™××•×ª (Todo API)** ××“×¨×’×™: Express + Postgres + Redis + Docker + Minikube.

### ××¨×›×™×˜×§×˜×•×¨×”
```
[Client] --> [Nginx LB] --> [Express Pods x3] --> [Postgres Replica] + [Redis Cluster]
                                           |
                                       [BullMQ Workers]
```
- **Microservices**: auth-service, todo-service (×‘×¢×ª×™×“).
- **Scaling**: HPA ×‘-K8s.

### ×§×•×“ ××œ×: `app.js`
```javascript
const express = require('express');
const { Pool } = require('pg');
const redis = require('redis');
const Queue = require('bullmq').Queue;
const app = express();
app.use(express.json());

const pool = new Pool({
  user: 'backend_user',
  host: process.env.DB_HOST || 'localhost',
  database: 'scalable_backend',
  password: 'securepass',
  port: 5432,
});

const redisClient = redis.createClient({ url: process.env.REDIS_URL || 'redis://localhost:6379' });
redisClient.connect();

const todoQueue = new Queue('todos', { connection: redisClient });

// Middleware for rate limiting (simple)
app.use((req, res, next) => {
  const ip = req.ip;
  // Implement Redis-based rate limit here
  next();
});

// GET /todos
app.get('/todos', async (req, res) => {
  const cached = await redisClient.get('todos');
  if (cached) return res.json(JSON.parse(cached));

  const { rows } = await pool.query('SELECT * FROM todos');
  await redisClient.setEx('todos', 300, JSON.stringify(rows));
  res.json(rows);
});

// POST /todos (async process)
app.post('/todos', async (req, res) => {
  const { title, description } = req.body;
  const { rows } = await pool.query(
    'INSERT INTO todos (title, description) VALUES ($1, $2) RETURNING *',
    [title, description]
  );
  await todoQueue.add('process', { id: rows[0].id });  // Async notification
  res.status(201).json(rows[0]);
});

app.listen(3000, () => console.log('Todo API on 3000'));
```

### DB Schema (×”×¨×¥ ×‘-psql):
```sql
CREATE TABLE todos (
  id SERIAL PRIMARY KEY,
  title VARCHAR(255) NOT NULL,
  description TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Docker + K8s
`Dockerfile`:
```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
CMD ["node", "app.js"]
```

`k8s-deployment.yaml`:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: todo-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: todo-api
  template:
    metadata:
      labels:
        app: todo-api
    spec:
      containers:
      - name: todo-api
        image: todo-api:latest
        ports:
        - containerPort: 3000
        env:
        - name: DB_HOST
          value: "postgres-service"
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: todo-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: todo-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

×¤×¨×¡: `minikube start`, `kubectl apply -f k8s-deployment.yaml`.

×‘×“×•×§: `minikube service todo-api`.

## âš™ï¸ ××•×¤×˜×™××™×–×¦×™×” ×•×‘×™×¦×•×¢×™×

### ×˜×™×¤×™× ×œ×‘×™×¦×•×¢×™×
1. **Clustering**: ×”×©×ª××© ×‘-PM2: `pm2 start server.js -i max`.
2. **Connection Pooling**: ×”×’×“×¨ `pool: { max: 20 }` ×‘-PG.
3. **Database Indexing**:
   ```sql
   CREATE INDEX idx_todos_created_at ON todos(created_at);
   ```
4. **Async/Await Everywhere**: ×”×™×× ×¢ ×-blocking code.
5. **CDN + Edge Caching**: Cloudflare ×œ-static assets.

### Benchmarks (×“×•×’××” ×¢× Apache Bench)
```
ab -n 10000 -c 100 http://localhost:80/todos
# Monolith: 500 req/s
# Scaled: 5000+ req/s ×¢× 3 replicas
```

### Best Practices
- **12-Factor App**: Config ×‘-env vars.
- **Health Checks**: `/health` endpoint.
- **Monitoring**: Prometheus + Grafana.
- **Profiling**: `clinic.js` ×œ-Node: `clinic doctor -- node app.js`.

> **×˜×™×¤ ×–×”×‘**: ×”×©×ª××© ×‘-**eBPF** (BCC tools) ×œ-profiling kernel-level.

## ğŸ› ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª × ×¤×•×¦×•×ª

### ×‘×¢×™×” 1: Memory Leaks ×‘-Node.js
**×¡×™××¤×˜×•××™×**: RAM ×’×“×œ ×œ×œ× ×’×‘×•×œ, crashes.
**×¤×ª×¨×•×Ÿ**:
```bash
npm i clinic.js
clinic doctor -- node app.js  # Analyze heap
```
×”×•×¡×£ `process.on('uncaughtException', () => process.exit(1));`.

### ×‘×¢×™×” 2: DB Connection Exhaustion
**×¡×™××¤×˜×•××™×**: "too many connections".
**×¤×ª×¨×•×Ÿ**: ×”×’×“×¨ pool limits + PgBouncer:
```yaml
# docker-compose: pgbouncer service
```

### ×‘×¢×™×” 3: Redis Out of Memory
**×¡×™××¤×˜×•××™×**: OOMKilled.
**×¤×ª×¨×•×Ÿ**:
```bash
redis-cli CONFIG SET maxmemory 2gb
redis-cli CONFIG SET maxmemory-policy allkeys-lru
```

### ×‘×¢×™×” 4: K8s Pods Crashing
**×¡×™××¤×˜×•××™×**: `kubectl logs` ××¨××” exit 137.
**×¤×ª×¨×•×Ÿ**: ×”×’×“×¨ resources ×‘-deployment:
```yaml
resources:
  limits:
    memory: "512Mi"
```

### ×‘×¢×™×” 5: High Latency ×‘-Load Balancer
**×¡×™××¤×˜×•××™×**: >200ms response.
**×¤×ª×¨×•×Ÿ**: Nginx `proxy_buffering on; keepalive 32;`.

## ğŸ” ××‘×˜×—×” ×•-Best Practices

### ×˜×™×¤×™× ×¡×¤×¦×™×¤×™×™×
- **JWT Auth**:
  ```javascript
  const jwt = require('jsonwebtoken');
  app.use('/protected', (req, res, next) => {
    const token = req.header('Authorization')?.replace('Bearer ', '');
    if (!token || !jwt.verify(token, process.env.JWT_SECRET)) return res.status(401).send('Unauthorized');
    next();
  });
  ```
- **Helmet**: `npm i helmet`; `app.use(helmet());`.
- **Rate Limiting**: `express-rate-limit`.
- **HTTPS**: Let's Encrypt + Nginx.
- **Secrets**: Vault ××• AWS Secrets Manager.

### Do's and Don'ts
| Do's | Don'ts |
|------|--------|
| ×”×©×ª××© ×‘-env vars ×œ-secrets | Hardcode passwords |
| Validate inputs (Joi/Zod) | SQL queries ×™×©×™×¨×•×ª |
| CORS policy ×§×¤×“× ×™×ª | `*` origins |
| Audit logs | Ignore vulnerabilities (npm audit) |

> **××–×”×¨×”**: ×¡×¨×•×§ ×ª×œ×•×ª ×¢× `npm audit` ×•-Snyk ×™×•××™.

## ğŸ“š ×¡×™×›×•× ×•××©××‘×™×

### ×¡×™×›×•× ×”× ×§×•×“×•×ª ×”××¨×›×–×™×•×ª
- **××“×¨×’×™×•×ª**: Clustering, Load Balancing, Auto-scaling.
- **×××™× ×•×ª**: Caching, Queues, Circuit Breakers.
- **×¤×¨×™×¡×”**: Docker + K8s ×œ×¤×¨×•×“×§×©×Ÿ.
- **×‘×™×¦×•×¢×™×**: Profiling, Indexing, Async.
- **×¤×¨×•×™×§×˜**: Todo API ×›×“×•×’××” end-to-end.

### ×¦×¢×“×™× ×”×‘××™×
1. ×œ××“ **Kubernetes** ×œ×¢×•××§ (certified CKAD).
2. ×‘× ×” microservices ×¢× **Istio** service mesh.
3. × ×¡×” **Serverless** ×‘-AWS/GCP.
4. ×ª×¨×’×œ ×¢× **Locust** ×œ-load testing.

### ××©××‘×™×
- **×“×•×§×•×× ×˜×¦×™×”**: [Node.js Clustering](https://nodejs.org/api/cluster.html), [Kubernetes Docs](https://kubernetes.io/docs/)
- **×§×•×¨×¡×™×**: freeCodeCamp Kubernetes, Udacity Scalable Microservices
- **×§×”×™×œ×•×ª**: Reddit r/devops, CNCF Slack, Stack Overflow
- **×¡×¤×¨×™×**: "Designing Data-Intensive Applications" by Martin Kleppmann

(×¡×”"×› ××™×œ×™×: ~4200)