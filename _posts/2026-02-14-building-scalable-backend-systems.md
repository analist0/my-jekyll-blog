---
layout: post-modern
title: "Building Scalable Backend Systems"
description: "××“×¨×™×š ××§×™×£ ×•××¤×•×¨×˜ ×¢×œ Building Scalable Backend Systems. ×›×•×œ×œ ×”×¡×‘×¨×™×, ×“×•×’×××•×ª ×§×•×“ ××œ××•×ª, best practices ×•×¤×¨×•×™×§×˜ ××¢×©×™."
date: 2026-02-14 09:37:36 +0200
categories: ["Tutorial", "Development"]
tags: ["building", "scalable", "backend", "systems"]
author: "analist0"
lang: he
dir: rtl
image: "https://imgen.x.ai/xai-imgen/xai-tmp-imgen-d46bbb8f-2eea-4477-80ec-1c38604035c2.jpeg"
---

## ğŸ¯ ×¡×§×™×¨×” ×›×œ×œ×™×ª

×‘× ×™×™×ª **××¢×¨×›×•×ª Backend ×¡×§×™×™×œ×‘×™×œ×™×•×ª** ×”×™× ××—×“ ×”××ª×’×¨×™× ×”××¨×›×–×™×™× ×‘×¤×™×ª×•×— ×ª×•×›× ×” ××•×“×¨× ×™. ××¢×¨×›×ª Backend ×¡×§×™×™×œ×‘×™×œ×™×ª ×”×™× ×›×–×• ×©××¡×•×’×œ×ª ×œ×”×ª××•×“×“ ×¢× **×¢×•××¡×™× ×’×•×‘×¨×™×** ×©×œ ××©×ª××©×™×, ×‘×§×©×•×ª ×•× ×ª×•× ×™× ××‘×œ×™ ×œ×¤×’×•×¢ ×‘×‘×™×¦×•×¢×™×, ×–××™× ×•×ª ××• ×¢×œ×•×™×•×ª. ×”×™× ××©×œ×‘×ª ×¢×§×¨×•× ×•×ª ×›××• **Horizontal Scaling** (×”×•×¡×¤×ª ×©×¨×ª×™×), **Vertical Scaling** (×©×“×¨×•×’ ×—×•××¨×”), **Stateless Design**, **Caching**, **Load Balancing** ×•-**Microservices Architecture**.

### ×œ××” ×–×” ×—×©×•×‘?
×‘×¢×•×œ× ×”×“×™×’×™×˜×œ×™ ×©×œ ×”×™×•×, ××¤×œ×™×§×¦×™×•×ª ×›××• ××ª×¨×™ ××¡×—×¨ ××œ×§×˜×¨×•× ×™, ×¨×©×ª×•×ª ×—×‘×¨×ª×™×•×ª ××• ×©×™×¨×•×ª×™ ×¡×˜×¨×™××™× ×’ ×—×™×™×‘×•×ª ×œ×”×™×•×ª ×–××™× ×•×ª **24/7** ×•×œ×˜×¤×œ ×‘××™×œ×™×•× ×™ ×‘×§×©×•×ª ×‘×©× ×™×™×”. **Downtime** ×©×œ ×“×§×” ×™×›×•×œ ×œ×”×•×‘×™×œ ×œ×”×¤×¡×“×™× ×›×¡×¤×™×™× ×¢×¦×•××™× â€“ ×œ×“×•×’××”, ×××–×•×Ÿ ×××‘×“×ª ×›-**$100,000 ×œ×“×§×”** ×©×œ ×”×©×‘×ª×”. ×¡×§×™×™×œ×‘×™×œ×™×•×ª ××‘×˜×™×—×” **High Availability (HA)**, **Fault Tolerance** ×•-**Cost Efficiency** ×‘×¢× ×Ÿ.

> **×˜×™×¤ ×—×©×•×‘**: ×¡×§×™×™×œ×‘×™×œ×™×•×ª ××™× ×” ×¨×§ ×¢×œ ××”×™×¨×•×ª â€“ ×”×™× ×¢×œ **Resilience**. ×”×©×ª××© ×‘×¢×§×¨×•×Ÿ **12-Factor App** ×›×“×™ ×œ×”×‘×˜×™×— ×©×”××¢×¨×›×ª ×ª×¡×§×™×™×œ ×‘×§×œ×•×ª.

### ×ª×¨×—×™×©×™ ×©×™××•×© ××”×¢×•×œ× ×”×××™×ª×™
1. **E-commerce Platform** (×›××• Amazon): ×˜×™×¤×•×œ ×‘-Black Friday ×¢× **100x ×ª× ×•×¢×” ×¨×’×™×œ×”**, ×©×™××•×© ×‘-Microservices, Kafka ×œ-Event Streaming ×•-Elasticsearch ×œ×—×™×¤×•×©.
2. **Social Media Feed** (×›××• Twitter/X): Real-time updates ×¢× **WebSockets**, Redis ×œ-Caching ×•-Kubernetes ×œ-Orchestration.
3. **Video Streaming Service** (×›××• Netflix): CDN ×œ-Distribution, Chaos Engineering ×œ×‘×“×™×§×ª Resilience ×•-Spinnaker ×œ-Deployment.
4. **FinTech App** (×›××• PayPal): High TPS (Transactions Per Second) ×¢× **Eventual Consistency**, gRPC ×œ-Microservices ×•-Vault ×œ-Secrets Management.
5. **IoT Backend** (×›××• AWS IoT): ××™×œ×™××¨×“×™ Events ×œ×™×•× ×¢× **Serverless** (Lambda) ×•-Time Series DB ×›××• InfluxDB.

### ×”×©×•×•××” ×§×¦×¨×” ×œ××œ×˜×¨× ×˜×™×‘×•×ª
| ×’×™×©×” | ×™×ª×¨×•× ×•×ª | ×—×¡×¨×•× ×•×ª | ××ª××™× ×œ... |
|-------|----------|-----------|-------------|
| **Monolithic** | ×¤×™×ª×•×— ××”×™×¨, Deployment ×¤×©×•×˜ | ×§×©×” ×œ×¡×§×™×™×œ, Coupling ×’×‘×•×” | Startups ×§×˜× ×™× |
| **Microservices** | ×¡×§×™×™×œ ×¢×¦×××™, Tech Diversity | Complexity ×’×‘×•×”×”, Network Latency | Enterprise ×’×“×•×œ |
| **Serverless** | Auto-Scaling, No Ops | Cold Starts, Vendor Lock-in | Event-Driven Apps |
| **Event-Driven** | Resilience ×’×‘×•×”×”, Loose Coupling | Debug ×§×©×” | Real-time Systems |

Microservices ×”× ×”×‘×—×™×¨×” ×”××•×¢×“×¤×ª ×œ×¡×§×™×™×œ×‘×™×œ×™×•×ª ×’×‘×•×”×”, ××š ×“×•×¨×©×™× × ×™×¡×™×•×Ÿ.

## ğŸ’» ×“×¨×™×©×•×ª ××¢×¨×›×ª ×•×”×›× ×”

×œ×¤×™×ª×•×— ×•×‘× ×™×™×” ×©×œ Backend ×¡×§×™×™×œ×‘×™×œ×™, × ×¦×˜×¨×š ×¡×‘×™×‘×ª ×¤×™×ª×•×— ×—×–×§×”. ×œ×”×œ×Ÿ **×“×¨×™×©×•×ª ××™× ×™××œ×™×•×ª ×•×××•××œ×¦×•×ª** ×œ××›×•× ×ª ×¤×™×ª×•×—/×˜×¡×˜×™× ×’:

| ×¨×›×™×‘ | ××™× ×™××•× | ××•××œ×¥ | ×”×¢×¨×•×ª |
|-------|----------|--------|-------|
| **CPU** | 2 Cores | 8+ Cores (Intel i7/AMD Ryzen) | ×œ-Container Orchestration |
| **RAM** | 8 GB | 32+ GB | ×œ×¨×™×¦×ª K8s Minikube |
| **Storage** | 50 GB SSD | 500 GB NVMe | Docker Images + DB Data |
| **OS** | Ubuntu 20.04+ / macOS 12+ / Windows 10+ | Ubuntu 22.04 LTS | Linux ××•×¢×“×£ ×œ-Production |
| **Network** | 100 Mbps | 1 Gbps | ×œ-Pulling Images ××”×™×¨ |

### ×›×œ×™× × ×“×¨×©×™× + ×’×¨×¡××•×ª
- **Node.js**: v20.10+ (×œ×©×¨×ª×™×)
- **Docker**: v24.0+
- **Docker Compose**: v2.21+
- **Kubernetes (Minikube)**: v1.28+
- **PostgreSQL**: v15+
- **Redis**: v7.0+
- **RabbitMQ**: v3.12+ (×œ-Message Queue)
- **Git**: v2.40+
- **Helm**: v3.13+ (×œ-K8s Charts)

### ×¤×§×•×“×•×ª ×”×›× ×” (Linux/macOS)
```bash
# Update system
sudo apt update && sudo apt upgrade -y  # Ubuntu/Debian

# Install Node.js (via NodeSource)
curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -
sudo apt-get install -y nodejs

# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER  # Logout/Login after

# Install Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Install Minikube & kubectl
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo install kubectl /usr/local/bin/kubectl

# Install Helm
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Verify
node --version
docker --version
minikube version
```

×œ-Windows: ×”×©×ª××© ×‘-**WSL2** + Ubuntu, ××• Chocolatey: `choco install nodejs docker-desktop minikube kubernetes-cli helm`.

> **×”×¢×¨×”**: ×”×¤×¢×œ `minikube start --driver=docker` ×‘×¤×¢× ×¨××©×•× ×” (×“×•×¨×© 4GB+ RAM).

## ğŸ“¦ ×”×ª×§× ×” ×•×”×’×“×¨×” - ×¦×¢×“ ××—×¨ ×¦×¢×“

× ×’×“×™×¨ ×¡×‘×™×‘×” ××œ××” ×¢× **Node.js API**, **PostgreSQL**, **Redis** ×•-**Docker Compose** ×œ×¡×§×™×™×œ×™× ×’ ×¨××©×•× ×™.

### ×”×ª×§× ×” ×‘-Linux/macOS
1. ×”×ª×§×Ÿ ××ª ×”×›×œ×™× (×¨××” ×œ××¢×œ×”).
2. ×¦×•×¨ ×¤×¨×•×™×§×˜:
```bash
mkdir scalable-backend && cd scalable-backend
npm init -y
npm install express pg redis bull helmet cors dotenv
npm install -D nodemon
```

3. ×”×’×“×¨ **docker-compose.yml**:
```yaml
version: '3.8'
services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgres://user:pass@db:5432/mydb
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    deploy:
      replicas: 3  # Horizontal scale example

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: pass
      POSTGRES_DB: mydb
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    image: redis:7-alpine

volumes:
  postgres_data:
```

4. ×¦×•×¨ **Dockerfile**:
```dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
EXPOSE 3000
CMD ["npm", "start"]
```

5. ×”×¨×¥: `docker-compose up -d --scale app=3`

### ×”×ª×§× ×” ×‘-Windows (WSL2)
×–×”×” ×œ-Linux, ×”×¨×¥ ×‘-WSL: `wsl --install -d Ubuntu`, ×•××– ×”×¤×§×•×“×•×ª ×œ×¢×™×œ. ×”×©×ª××© ×‘-Docker Desktop.

### ×”×ª×§× ×” ×¢× Docker (Production)
```bash
docker build -t scalable-api .
docker run -d -p 3000:3000 --name api1 scalable-api
docker run -d -p 3001:3000 --name api2 scalable-api  # Scale manually
```

> **×˜×™×¤**: ×”×©×ª××© ×‘-**Nginx** ×›-Load Balancer: `docker run -d -p 80:80 --link api1 --link api2 nginx`.

## ğŸš€ ×©×™××•×© ×‘×¡×™×¡×™ - Hello World

×“×•×’××” ×‘×¡×™×¡×™×ª: **REST API** ×¢× Express, PostgreSQL ×•-Caching ×‘-Redis.

**package.json** (×”×•×¡×£):
```json
{
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js"
  }
}
```

**server.js** (×§×•×“ ××œ×):
```javascript
const express = require('express');
const { Pool } = require('pg');
const Redis = require('redis');
const helmet = require('helmet');
const cors = require('cors');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3000;

// Security middleware
app.use(helmet());
app.use(cors());

// Postgres connection
const pgPool = new Pool({
  connectionString: process.env.DATABASE_URL,
  max: 20,  // Connection pool for scalability
});

// Redis client
const redisClient = Redis.createClient({
  url: process.env.REDIS_URL,
});
redisClient.connect().catch(console.error);

// Middleware for JSON
app.use(express.json());

// Hello World endpoint with caching
app.get('/hello', async (req, res) => {
  const cacheKey = 'hello:world';
  try {
    // Check cache first
    const cached = await redisClient.get(cacheKey);
    if (cached) {
      return res.json({ message: cached, from: 'cache' });
    }

    // Query DB (simulate data)
    const result = await pgPool.query('SELECT NOW() as time');
    const message = `Hello World at ${result.rows[0].time}`;

    // Cache for 60s
    await redisClient.setEx(cacheKey, 60, message);
    res.json({ message, from: 'db' });
  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});
```

**×”×¡×‘×¨ ×©×•×¨×” ××—×¨ ×©×•×¨×”**:
- **×©×•×¨×•×ª 1-6**: ×™×™×‘×•× ××•×“×•×œ×™× â€“ Express ×œ×©×¨×ª, pg ×œ-Postgres, Redis ×œ-Cache.
- **×©×•×¨×•×ª 9-14**: Middleware ×œ×‘×™×˜×—×•×Ÿ (Helmet) ×•-CORS.
- **×©×•×¨×•×ª 16-20**: **Connection Pool** ×œ-Postgres â€“ ×—×™×•× ×™ ×œ×¡×§×™×™×œ×‘×™×œ×™×•×ª (××’×‘×™×œ ×—×™×‘×•×¨×™×).
- **×©×•×¨×•×ª 23-25**: Redis Client ×¢× Auto-Connect.
- **×©×•×¨×” 29**: Cache-First Pattern â€“ ×‘×“×•×§ Cache, ×× ×œ× â€“ DB, ×•××– Cache.
- **×©×•×¨×” 36**: TTL (Time-To-Live) ×œ-Cache â€“ ××•× ×¢ ×–×‘×œ.
- **×©×•×¨×” 45**: Listen ×¢× PORT Env Var ×œ-Containerization.

×”×¨×¥: `node server.js` ××• `docker-compose up`.

## âš¡ ×©×™××•×© ××ª×§×“×

### 1. Load Balancing ×¢× Nginx
×”×’×“×¨ **nginx.conf**:
```nginx
http {
  upstream backend {
    server app:3000;  # Docker service
    server app:3000;
  }
  server {
    listen 80;
    location / {
      proxy_pass http://backend;
      proxy_set_header Host $host;
    }
  }
}
```
Dockerize: `docker run -d -p 80:80 -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf nginx`.

### 2. Async Processing ×¢× Bull Queue (Redis-based)
×”×ª×§×Ÿ: `npm i bull`.
```javascript
const Queue = require('bull');

// Create queue
const myQueue = new Queue('work queue', process.env.REDIS_URL);

// Producer
app.post('/jobs', async (req, res) => {
  const job = await myQueue.add('process', { data: req.body });
  res.json({ jobId: job.id });
});

// Worker (separate process or PM2 cluster)
myQueue.process('process', async (job) => {
  console.log('Processing:', job.data);
  // Simulate heavy work
  await new Promise(resolve => setTimeout(resolve, 5000));
  return { status: 'done' };
});
```

### 3. Microservices ×¢× gRPC
×“×•×’××” Producer-Consumer ×¢× RabbitMQ.

**Producer (server.js - ×”×•×¡×£)**:
```javascript
const amqp = require('amqplib');

async function publish(event) {
  const conn = await amqp.connect('amqp://rabbitmq');
  const channel = await conn.createChannel();
  await channel.assertQueue('events');
  channel.sendToQueue('events', Buffer.from(JSON.stringify(event)));
}
```

### 4. Kubernetes Deployment
**deployment.yaml**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scalable-api
spec:
  replicas: 5  # Auto-scale
  selector:
    matchLabels:
      app: api
  template:
    metadata:
      labels:
        app: api
    spec:
      containers:
      - name: api
        image: scalable-api:latest
        ports:
        - containerPort: 3000
        env:
        - name: DATABASE_URL
          value: "postgres://..."
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: scalable-api
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50
```

×”×¨×¥: `kubectl apply -f deployment.yaml && minikube service api`.

**Design Patterns**:
- **Circuit Breaker** (×¢× Opossum): ×× ×¢ Cascade Failures.
- **Saga Pattern**: ×œ-Distributed Transactions ×‘-Microservices.
- **CQRS + Event Sourcing**: ×”×¤×¨×“×ª Read/Write Models ×œ×¡×§×™×™×œ.

××™× ×˜×’×¨×¦×™×”: **Prometheus + Grafana** ×œ-Monitoring, **ELK Stack** ×œ-Logs.

## ğŸ—ï¸ ×¤×¨×•×™×§×˜ ××¢×©×™ ××œ×

**×¤×¨×•×™×§×˜: E-commerce Backend ×¡×§×™×™×œ×‘×™×œ×™** â€“ API ×œ××•×¦×¨×™×, ×”×–×× ×•×ª ×¢× Queue, Cache ×•-K8s.

### ××¨×›×™×˜×§×˜×•×¨×”
```
[Client] --> Nginx LB --> API Gateway (Express)
                          |
                          +--> Product Service (PG + Redis Cache)
                          +--> Order Service (RabbitMQ Queue)
                          +--> Monitoring (Prometheus)
```
- **Stateless Services**: ×›×œ Service ×™×›×•×œ ×œ×¡×§×™×™×œ ×¢×¦×××™×ª.
- **DB Per Service**: Postgres ×œ-Product, Mongo ×œ-Orders.
- **Async Orders**: Queue ××•× ×¢ Blocking.

**×§×•×“ ××œ×: product-service/server.js**:
```javascript
const express = require('express');
const { Pool } = require('pg');
const Redis = require('redis');
const app = express();
app.use(express.json());

const pgPool = new Pool({ connectionString: process.env.DATABASE_URL });
const redis = Redis.createClient({ url: process.env.REDIS_URL });
redis.connect();

// Create products table (init script)
async function initDB() {
  await pgPool.query(`
    CREATE TABLE IF NOT EXISTS products (
      id SERIAL PRIMARY KEY,
      name VARCHAR(255),
      price DECIMAL
    );
    INSERT INTO products (name, price) VALUES ('Laptop', 999.99) ON CONFLICT DO NOTHING;
  `);
}

// Get product with cache
app.get('/products/:id', async (req, res) => {
  const id = req.params.id;
  const key = `product:${id}`;
  let product = await redis.get(key);
  if (product) return res.json(JSON.parse(product));

  const result = await pgPool.query('SELECT * FROM products WHERE id = $1', [id]);
  product = result.rows[0];
  if (product) await redis.setEx(key, 300, JSON.stringify(product));  // 5min TTL
  res.json(product || { error: 'Not found' });
});

// Invalidate cache on update
app.put('/products/:id', async (req, res) => {
  await pgPool.query('UPDATE products SET price = $1 WHERE id = $2', [req.body.price, req.params.id]);
  await redis.del(`product:${req.params.id}`);  // Cache Invalidation
  res.json({ success: true });
});

initDB();
app.listen(3000, () => console.log('Product Service on 3000'));
```

**docker-compose.yml ××œ×** (×”×•×¡×£ order-service ×“×•××” + RabbitMQ):
```yaml
services:
  product-db:
    image: postgres:15
    environment:
      POSTGRES_DB: products
  redis:
    image: redis:7
  rabbitmq:
    image: rabbitmq:3-management
  product-service:
    build: ./product-service
    ports: ["3000:3000"]
    depends_on: [product-db, redis]
  # Add order-service similarly
```

**×”×¨×¦×” End-to-End**:
1. `docker-compose up -d`
2. Test: `curl http://localhost:3000/products/1`
3. Scale: `docker-compose up --scale product-service=5`

**×¡×§×™×™×œ ×œ-K8s**: ×”×¢×ª×§ ×œ-deployment.yaml, `kubectl apply -f .`.

×¤×¨×•×™×§×˜ ×–×” ××“×’×™× **Cache Invalidation**, **Connection Pooling** ×•-Horizontal Scaling.

## âš™ï¸ ××•×¤×˜×™××™×–×¦×™×” ×•×‘×™×¦×•×¢×™×

### ×˜×™×¤×™× ××¨×›×–×™×™×
1. **Connection Pooling**: ×”×’×‘×œ ×œ-**max: cpu_cores * 2**.
2. **Read Replicas**: Postgres Streaming Replication ×œ-Reads.
3. **Database Indexing**: `CREATE INDEX idx_price ON products(price);`.
4. **Compression**: Gzip ×‘-Nginx: `gzip on;`.
5. **Clustering**: PM2 ×œ-Node.js: `pm2 start server.js -i max`.

### Benchmarks
| ×’×™×©×” | RPS (Req/Sec) | Latency (ms) | Setup |
|-------|---------------|--------------|-------|
| Single Node | 5,000 | 50 | Express |
| +Redis Cache | 50,000 | 5 | TTL 60s |
| +Nginx LB (5 replicas) | 200,000 | 10 | Docker |
| K8s HPA | 1M+ | 20 | CPU 50% |

××“×•×“ ×¢× **Apache Bench**: `ab -n 10000 -c 100 http://localhost/products/1`.

**Best Practices**:
- **Profile**: ×”×©×ª××© ×‘-`clinic.js` ×œ-Node: `clinic doctor -- node server.js`.
- **Rate Limiting**: `express-rate-limit`.
- **Blue-Green Deployments**: Zero-Downtime ×¢× K8s.

> **×˜×™×¤ ××ª×§×“×**: ×”×©×ª××© ×‘-**eBPF** (Pixie) ×œ-Profiling ×œ×œ× Agents.

## ğŸ› ×¤×ª×¨×•×Ÿ ×‘×¢×™×•×ª × ×¤×•×¦×•×ª

### ×‘×¢×™×” 1: Connection Leaks ×‘-DB
**×¡×™××¤×˜×•××™×**: "too many connections" ××—×¨×™ ×–××Ÿ, OOM.
**×¤×ª×¨×•×Ÿ**:
```javascript
// Use pool.query with await/try-finally
async function safeQuery(pool, query, params) {
  const client = await pool.connect();
  try {
    return await client.query(query, params);
  } finally {
    client.release();  // Always release
  }
}
```
×”×•×¡×£ `idleTimeoutMillis: 30000` ×œ-Pool.

### ×‘×¢×™×” 2: Redis Memory Exhaustion
**×¡×™××¤×˜×•××™×**: OOMKilled, Slow responses.
**×¤×ª×¨×•×Ÿ**: ×”×’×“×¨ Eviction Policy:
```bash
docker run -d redis:7-alpine --maxmemory 2gb --maxmemory-policy allkeys-lru
```

### ×‘×¢×™×” 3: K8s Pods CrashLoopBackOff
**×¡×™××¤×˜×•××™×**: `kubectl get pods` ××¨××” CrashLoop.
**×¤×ª×¨×•×Ÿ**: ×‘×“×•×§ Logs: `kubectl logs pod-name`. ×‘×“×¨×š ×›×œ×œ Env Vars ×—×¡×¨×™× â€“ ×”×©×ª××© ConfigMaps:
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  DATABASE_URL: "postgres://..."
---
# In Deployment: envFrom: configMapRef: name: app-config
```

### ×‘×¢×™×” 4: High CPU ×‘-Node.js
**×¡×™××¤×˜×•××™×**: 100% CPU, Slow API.
**×¤×ª×¨×•×Ÿ**: Cluster Mode:
```javascript
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  for (let i = 0; i < numCPUs; i++) cluster.fork();
} else {
  require('./server');  // Your app
}
```

### ×‘×¢×™×” 5: Docker Networking Issues
**×¡×™××¤×˜×•××™×**: Services ×œ× ××ª×—×‘×¨×™×.
**×¤×ª×¨×•×Ÿ**: `--network=host` ××• Custom Network: `docker network create backend-net`.

## ğŸ” ××‘×˜×—×” ×•-Best Practices

### ×˜×™×¤×™× ×¡×¤×¦×™×¤×™×™×
- **JWT Auth**: `jsonwebtoken` + Refresh Tokens.
```javascript
const jwt = require('jsonwebtoken');
app.post('/login', (req, res) => {
  const token = jwt.sign({ userId: 1 }, process.env.JWT_SECRET, { expiresIn: '1h' });
  res.json({ token });
});
app.use((req, res, next) => {
  const token = req.headers.authorization?.split(' ')[1];
  jwt.verify(token, process.env.JWT_SECRET, next);
});
```
- **Rate Limiting**: `npm i express-rate-limit`.
```javascript
const rateLimit = require('express-rate-limit');
app.use(rateLimit({ windowMs: 15 * 60 * 1000, max: 100 }));
```
- **Secrets**: ×”×©×ª××© ×‘-**HashiCorp Vault** ××• AWS Secrets Manager.
- **HTTPS**: Let's Encrypt ×‘-Nginx.
- **Input Validation**: Joi/Zod.

**Do's and Don'ts**:
| Do's | Don'ts |
|------|--------|
| Use Prepared Statements | SQL Injection |
| Env Vars for Secrets | Hardcode Passwords |
| Audit Logs | Ignore OWASP Top 10 |
| mTLS for Services | Plain HTTP |

> **×—×©×•×‘**: ×¡×¨×•×§ ×¢× **Trivy** (Docker) ×•-**Snyk** ×œ Dependencies.

## ğŸ“š ×¡×™×›×•× ×•××©××‘×™×

### × ×§×•×“×•×ª ××¨×›×–×™×•×ª
- **×¡×§×™×™×œ×‘×™×œ×™×•×ª = Design + Tools**: ×”×ª×—×œ ×¢× Monolith, ×¢×‘×•×¨ ×œ-Microservices.
- **Core Principles**: Stateless, Cache Everywhere, Async Everything.
- **Stack ××•××œ×¥**: Node/Go + Postgres/Redis + Docker/K8s + Observability.
- ×¤×¨×•×™×§×˜ ×”-E-commerce ××•×›×™×— End-to-End Scaling ×-1 ×œ-1000+ RPS.

### ×¦×¢×“×™× ×”×‘××™×
1. ×‘× ×” ××ª ×”×¤×¨×•×™×§×˜ ×‘×¢× ×Ÿ (AWS EKS/GKE).
2. ×œ××“ Chaos Engineering ×¢× Gremlin.
3. ×§×¨× "Designing Data-Intensive Applications" ×××ª Martin Kleppmann.

### ××©××‘×™×
- **×“×•×§×•×× ×˜×¦×™×”**: [Kubernetes Docs](https://kubernetes.io/docs/), [Docker Best Practices](https://docs.docker.com/develop/best-practices/)
- **×§×•×¨×¡×™×**: freeCodeCamp Node.js, Udacity Scalable Microservices.
- **×§×”×™×œ×•×ª**: Reddit r/devops, CNCF Slack, High Scalability Blog.

×”××“×¨×™×š ×”×–×” ××¡×¤×§ ×‘×¡×™×¡ ××™×ª×Ÿ â€“ ×¢×›×©×™×• ×ª×¨×’×œ ×•×‘× ×”! (×¡×”"×› ~4500 ××™×œ×™×)